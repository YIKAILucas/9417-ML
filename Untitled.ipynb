{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46d3436f-03f2-4059-b4dc-d45d8fe438f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, OrdinalEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43910062-ffdf-4fc1-81f8-7b292003dea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# HAN YIKAI\n",
    "\"\"\"\n",
    "This part is feature engineering. We encode some string features and extract useful features.\n",
    "\"\"\"\n",
    "rm_cols = ['ncodpers', 'ind_ahor_fin_ult1', 'ind_aval_fin_ult1', 'ind_cco_fin_ult1',\n",
    "           'ind_cder_fin_ult1', 'ind_cno_fin_ult1', 'ind_ctju_fin_ult1',\n",
    "           'ind_ctma_fin_ult1', 'ind_ctop_fin_ult1', 'ind_ctpp_fin_ult1',\n",
    "           'ind_deco_fin_ult1', 'ind_deme_fin_ult1', 'ind_dela_fin_ult1',\n",
    "           'ind_ecue_fin_ult1', 'ind_fond_fin_ult1', 'ind_hip_fin_ult1',\n",
    "           'ind_plan_fin_ult1', 'ind_pres_fin_ult1', 'ind_reca_fin_ult1',\n",
    "           'ind_tjcr_fin_ult1', 'ind_valo_fin_ult1', 'ind_viv_fin_ult1',\n",
    "           'ind_nomina_ult1', 'ind_nom_pens_ult1', 'ind_recibo_ult1']\n",
    "\n",
    "targetcols = ['ind_ahor_fin_ult1', 'ind_aval_fin_ult1', 'ind_cco_fin_ult1',\n",
    "              'ind_cder_fin_ult1', 'ind_cno_fin_ult1', 'ind_ctju_fin_ult1',\n",
    "              'ind_ctma_fin_ult1', 'ind_ctop_fin_ult1', 'ind_ctpp_fin_ult1',\n",
    "              'ind_deco_fin_ult1', 'ind_deme_fin_ult1', 'ind_dela_fin_ult1',\n",
    "              'ind_ecue_fin_ult1', 'ind_fond_fin_ult1', 'ind_hip_fin_ult1',\n",
    "              'ind_plan_fin_ult1', 'ind_pres_fin_ult1', 'ind_reca_fin_ult1',\n",
    "              'ind_tjcr_fin_ult1', 'ind_valo_fin_ult1', 'ind_viv_fin_ult1',\n",
    "              'ind_nomina_ult1', 'ind_nom_pens_ult1', 'ind_recibo_ult1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2589954f-3af8-4e97-b05c-5c83b09d7b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# pd.options.display.max_rows = 500\n",
    "# np.set_printoptions(threshold=500)\n",
    "\n",
    "\"\"\"\n",
    "Sampling according to sample proportion, because the current account is most frequently samples,\n",
    "and it lead to the number of samples to be unbalanced. \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def sample_pro(df):\n",
    "    new = df.iloc[0:1]\n",
    "    for i in targetcols:\n",
    "        if i == 'ind_cco_fin_ult1':\n",
    "            #         pass\n",
    "            continue\n",
    "        tmp = df.loc[df[i] == 1]\n",
    "        tmp = tmp[0:50000]\n",
    "        new = new.append(tmp, ignore_index=True)\n",
    "    # new.shape\n",
    "    return df\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "encode label and category features\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def process(data):\n",
    "    encoder_label = LabelEncoder()\n",
    "    encoder_ord = OrdinalEncoder()\n",
    "\n",
    "    data.loc[data['sexo'].isnull(), 'sexo'] = \"NA\"\n",
    "    # remove 3 unuseful or unapplicable features in our models\n",
    "    # print(f'rm fecha_alta, canal_entrada, fecha_dato')\n",
    "    data.drop(['fecha_alta', 'canal_entrada',\n",
    "               'fecha_dato'], axis=1, inplace=True)\n",
    "\n",
    "    # to be encoded labels\n",
    "    to_encode_colum_l = ['sexo', 'ind_nuevo', 'indresi', 'indext', 'indfall',\n",
    "                         'tiprel_1mes', 'ind_empleado', 'indrel_1mes', 'nomprov', 'pais_residencia']\n",
    "    # use encoder_label to encode the label features in alphabetical order\n",
    "    for i in to_encode_colum_l:\n",
    "        tmp = encoder_label.fit_transform(\n",
    "            list(data[i].values)).reshape(-1, 1)\n",
    "        data[i] = tmp.copy()\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def feature_extract(file):\n",
    "    limit_rows = 500000\n",
    "    df = pd.read_csv(file,\n",
    "                     dtype={\"sexo\": str,\n",
    "                            \"ind_nuevo\": str,\n",
    "                            \"ult_fec_cli_1t\": str,\n",
    "                            \"indext\": str},\n",
    "                     #                  nrows=limit_rows,\n",
    "                     low_memory=False)\n",
    "\n",
    "    df = df.sample(frac=1)\n",
    "    print(f'initial.shape {df.shape}')\n",
    "    data = process(df)\n",
    "    print(f'process data.shape {data.shape}')\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def split_label(data):\n",
    "    train_data = data.drop(rm_cols, axis=1)\n",
    "    train_label = data[targetcols]\n",
    "\n",
    "    return train_data, train_label\n",
    "\n",
    "\n",
    "def split_train_and_test(train_set, test_set):\n",
    "    train_X, test_X, train_y, test_y = train_test_split(train_set, test_set, test_size=0.5)\n",
    "\n",
    "    return train_X, train_y, test_X, test_y\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file = \"./processed_data.csv\"\n",
    "    data = feature_extract(file)\n",
    "    data.to_csv('./featured_data.csv')\n",
    "    # data.to_csv('./featured_data.csv')\n",
    "    # for model\n",
    "    # split train and test dataset \n",
    "    # train_set, test_set = split_label(data)\n",
    "    # train_x, train_y, test_x, test_y = split_train_and_test(train_set, test_set)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
