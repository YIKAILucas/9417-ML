{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from collections import defaultdict\n",
    "from sklearn import ensemble\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "random.seed(2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_time = datetime.datetime.now()\n",
    "\n",
    "usecols = ['ncodpers', 'ind_ahor_fin_ult1', 'ind_aval_fin_ult1', 'ind_cco_fin_ult1',\n",
    "       'ind_cder_fin_ult1', 'ind_cno_fin_ult1', 'ind_ctju_fin_ult1',\n",
    "       'ind_ctma_fin_ult1', 'ind_ctop_fin_ult1', 'ind_ctpp_fin_ult1',\n",
    "       'ind_deco_fin_ult1', 'ind_deme_fin_ult1', 'ind_dela_fin_ult1',\n",
    "       'ind_ecue_fin_ult1', 'ind_fond_fin_ult1', 'ind_hip_fin_ult1',\n",
    "       'ind_plan_fin_ult1', 'ind_pres_fin_ult1', 'ind_reca_fin_ult1',\n",
    "       'ind_tjcr_fin_ult1', 'ind_valo_fin_ult1', 'ind_viv_fin_ult1',\n",
    "       'ind_nomina_ult1', 'ind_nom_pens_ult1', 'ind_recibo_ult1']\n",
    "\n",
    "df_train = pd.read_csv('../input/train_ver2.csv', usecols=usecols)\n",
    "sample = pd.read_csv('../input/sample_submission.csv')\n",
    "\n",
    "df_train = df_train.drop_duplicates(['ncodpers'], keep='last')\n",
    "df_train.fillna(0, inplace=True)\n",
    "df_train=df_train.sample(frac=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ind_ahor_fin_ult1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_191490/2173343078.py:9: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train = df_train.drop([c, 'ncodpers'], 1)\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done   2 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=10)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [17], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m clf \u001b[38;5;241m=\u001b[39m ensemble\u001b[38;5;241m.\u001b[39mRandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, min_samples_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     13\u001b[0m clf\u001b[38;5;241m.\u001b[39mfit(x_train, y_train)\n\u001b[0;32m---> 14\u001b[0m p_train1 \u001b[38;5;241m=\u001b[39m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mid\u001b[39m, p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(ids, p_train1):\n\u001b[1;32m     18\u001b[0m     id_preds[\u001b[38;5;28mid\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(p)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 1 with size 1"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "model_preds = {}\n",
    "id_preds = defaultdict(list)\n",
    "ids = df_train['ncodpers'].values\n",
    "for c in df_train.columns:\n",
    "    if c != 'ncodpers':\n",
    "        print(c)\n",
    "        y_train = df_train[c]\n",
    "        x_train = df_train.drop([c, 'ncodpers'], 1)\n",
    "\n",
    "        clf = ensemble.RandomForestClassifier(n_estimators=10, n_jobs=-1,max_depth=3, min_samples_split=10, verbose=1)\n",
    "\n",
    "        clf.fit(x_train, y_train)\n",
    "        p_train1 = clf.predict_proba(x_train)[:,1]\n",
    "\n",
    "\n",
    "        for id, p in zip(ids, p_train1):\n",
    "            id_preds[id].append(p)\n",
    "\n",
    "        print(roc_auc_score(y_train, p_train1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.895188824503849e-05,\n",
       " 0.0,\n",
       " 0.6017605053997744,\n",
       " 0.00011758372408615737,\n",
       " 0.02227141047698755,\n",
       " 0.025410427923659284,\n",
       " 0.009217172746508302,\n",
       " 0.086135584244221,\n",
       " 0.018819712913914304,\n",
       " 4.208613015726851e-05,\n",
       " 9.843748769937972e-05,\n",
       " 0.011896029012087177,\n",
       " 0.03503976747874705,\n",
       " 0.003528843934282266,\n",
       " 0.0010793341813789005,\n",
       " 0.0028976633800283777,\n",
       " 0.0035725244816024395,\n",
       " 0.020257079593096156,\n",
       " 0.005248279119474489,\n",
       " 0.004907969518076183,\n",
       " 0.0013934295832246824,\n",
       " 0.00045061092900180766,\n",
       " 0.0019926865022331436,\n",
       " 0.016939969280392684]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = df_train['ncodpers'].values\n",
    "id_preds[1049700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ind_ahor_fin_ult1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_191490/2209401020.py:9: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train = df_train.drop([c, 'ncodpers'], 1)\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    2.9s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done  60 out of  60 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8394957617267711\n",
      "ind_aval_fin_ult1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_191490/2209401020.py:9: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train = df_train.drop([c, 'ncodpers'], 1)\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done  60 out of  60 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9980036017097537\n",
      "ind_cco_fin_ult1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_191490/2209401020.py:9: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train = df_train.drop([c, 'ncodpers'], 1)\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    2.7s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done  60 out of  60 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6540570651758734\n",
      "ind_cder_fin_ult1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_191490/2209401020.py:9: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train = df_train.drop([c, 'ncodpers'], 1)\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    2.9s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done  60 out of  60 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8070472950155613\n",
      "ind_cno_fin_ult1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_191490/2209401020.py:9: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train = df_train.drop([c, 'ncodpers'], 1)\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    2.9s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done  60 out of  60 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9713874435973664\n",
      "ind_ctju_fin_ult1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_191490/2209401020.py:9: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train = df_train.drop([c, 'ncodpers'], 1)\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    2.4s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done  60 out of  60 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8656175575557151\n",
      "ind_ctma_fin_ult1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_191490/2209401020.py:9: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train = df_train.drop([c, 'ncodpers'], 1)\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done  60 out of  60 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6689271273115713\n",
      "ind_ctop_fin_ult1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_191490/2209401020.py:9: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train = df_train.drop([c, 'ncodpers'], 1)\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done  60 out of  60 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6183817512417141\n",
      "ind_ctpp_fin_ult1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_191490/2209401020.py:9: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train = df_train.drop([c, 'ncodpers'], 1)\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done  60 out of  60 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7489652688526235\n",
      "ind_deco_fin_ult1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_191490/2209401020.py:9: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train = df_train.drop([c, 'ncodpers'], 1)\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done  60 out of  60 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9047084401993941\n",
      "ind_deme_fin_ult1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_191490/2209401020.py:9: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train = df_train.drop([c, 'ncodpers'], 1)\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done  60 out of  60 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8853776472705779\n",
      "ind_dela_fin_ult1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_191490/2209401020.py:9: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train = df_train.drop([c, 'ncodpers'], 1)\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    2.9s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done  60 out of  60 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7888005580897548\n",
      "ind_ecue_fin_ult1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_191490/2209401020.py:9: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train = df_train.drop([c, 'ncodpers'], 1)\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done  60 out of  60 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.780885413284162\n",
      "ind_fond_fin_ult1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_191490/2209401020.py:9: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train = df_train.drop([c, 'ncodpers'], 1)\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done  60 out of  60 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8591201852124782\n",
      "ind_hip_fin_ult1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_191490/2209401020.py:9: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train = df_train.drop([c, 'ncodpers'], 1)\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done  60 out of  60 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9271222964115047\n",
      "ind_plan_fin_ult1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_191490/2209401020.py:9: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train = df_train.drop([c, 'ncodpers'], 1)\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done  60 out of  60 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8542755936747217\n",
      "ind_pres_fin_ult1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_191490/2209401020.py:9: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train = df_train.drop([c, 'ncodpers'], 1)\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done  60 out of  60 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7323506640344777\n",
      "ind_reca_fin_ult1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_191490/2209401020.py:9: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train = df_train.drop([c, 'ncodpers'], 1)\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    2.9s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done  60 out of  60 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8379972194849705\n",
      "ind_tjcr_fin_ult1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_191490/2209401020.py:9: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train = df_train.drop([c, 'ncodpers'], 1)\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done  60 out of  60 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9076538187018706\n",
      "ind_valo_fin_ult1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_191490/2209401020.py:9: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train = df_train.drop([c, 'ncodpers'], 1)\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done  60 out of  60 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8453766613287724\n",
      "ind_viv_fin_ult1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_191490/2209401020.py:9: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train = df_train.drop([c, 'ncodpers'], 1)\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done  60 out of  60 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7894618244665167\n",
      "ind_nomina_ult1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_191490/2209401020.py:9: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train = df_train.drop([c, 'ncodpers'], 1)\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done  60 out of  60 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9981244939660792\n",
      "ind_nom_pens_ult1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_191490/2209401020.py:9: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train = df_train.drop([c, 'ncodpers'], 1)\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done  60 out of  60 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.998448048516636\n",
      "ind_recibo_ult1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_191490/2209401020.py:9: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  x_train = df_train.drop([c, 'ncodpers'], 1)\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done  60 out of  60 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8662788336637236\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m     row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(row)\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m row\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m     active \u001b[38;5;241m=\u001b[39m [c[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(df_train\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m1\u001b[39m:], row) \u001b[38;5;28;01mif\u001b[39;00m c[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     27\u001b[0m     already_active[\u001b[38;5;28mid\u001b[39m] \u001b[38;5;241m=\u001b[39m active\n\u001b[1;32m     29\u001b[0m train_preds \u001b[38;5;241m=\u001b[39m {}\n",
      "Cell \u001b[0;32mIn [3], line 26\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     24\u001b[0m     row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(row)\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m row\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m     active \u001b[38;5;241m=\u001b[39m [c[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(df_train\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m1\u001b[39m:], row) \u001b[38;5;28;01mif\u001b[39;00m c[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     27\u001b[0m     already_active[\u001b[38;5;28mid\u001b[39m] \u001b[38;5;241m=\u001b[39m active\n\u001b[1;32m     29\u001b[0m train_preds \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "already_active = {}\n",
    "for row in df_train.values:\n",
    "    row = list(row)\n",
    "    id = row.pop(0)\n",
    "    active = [c[0] for c in zip(df_train.columns[1:], row) if c[1] > 0]\n",
    "    already_active[id] = active\n",
    "\n",
    "train_preds = {}\n",
    "for id, p in id_preds.items():\n",
    "    # Here be dragons\n",
    "    preds = [i[0] for i in sorted([i for i in zip(df_train.columns[1:], p) if i[0] not in already_active[id]], key=lambda i:i [1], reverse=True)[:7]]\n",
    "    train_preds[id] = preds\n",
    "\n",
    "test_preds = []\n",
    "for row in sample.values:\n",
    "    id = row[0]\n",
    "    p = train_preds[id]\n",
    "    test_preds.append(' '.join(p))\n",
    "\n",
    "sample['added_products'] = test_preds\n",
    "\n",
    "sample.to_csv('RFC_sub.csv', index=False)\n",
    "print(datetime.datetime.now()-start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
